---
title:  "머신러닝(검증)"

categories:
  - 머신러닝
tags:
  - Blog

---

## Cross Validation

### 1. Train, Valid, Test Set

훈련, 검증, 테스트 데이터라고 부르는 3가지를 한번 이야기 해보겠습니다.<br>
* Train Data : 모델을 학습하는데 사용하는 데이터 (모델이 알고 있는 학습할 데이터)
* Valid Data : 학습한 모델의 성능을 검증하는 데이터 (모델이 모르는 학습하지 않을 데이터, 모델 검증에 사용하는 데이터)
* Test Data : 학습한 모델로 예측할 데이터 (모델이 모르는 예측할 데이터)

### 2. k-fold with stratify

k-fold는 데이터를 k개로 쪼개는 것을 말합니다. <br>
일반적으로 Cross Validation에서 사용되며, 데이터셋을 k개로 쪼개어 k-1개로 모델을 학습하고, 1개로 모델을 검증합니다. <br>
k개로 데이터를 쪼개면, 모든 fold에 대해(하나의 fold를 선택하여) 검증하는 방식으로 k번 다른 데이터셋으로 학습한 모델을 검증할 수 있습니다.


![GitHub Logo](/image/kfold.png)

#### Stratify, 계층적 k-fold

k-fold는 데이터의 정렬 유무와 분류할 클래스의 비율에 상관없이 순서대로 데이터를 분할하는 특징이 있습니다.<br>
하지만, 분류할 클래스의 비율이 다르다면 어떻게 될까요? 그런 경우에는, 각 fold가 학습 데이터셋을 대표한다고 말하기 어려워집니다.<br>
한 fold에 특정 클래스가 많이 나올수도, 적게 나올수도 있기 때문입니다. Stratified k-fold는 그러한 문제점을 해결하기 위해 제안되었습니다.<br>
k개의 fold도 분할한 이후에도, 전체 훈련 데이터의 클래스 비율과 각 fold가 가지고 있는 클래스의 비율을 맞추어 준다는 점이 기존의 k-fold와의 다른 특징 입니다.

k-fold는 sklearn의 model_selection 패키지에 있습니다.

#### Cross Validation

1. 데이터 집합을 k개의 데이터 Fold로 나눕니다.
(k-1)개의 Fold는 훈련 Fold, 1개는 검증 Fold로 지정합니다.
2. 훈련 Fold를 이용하여 모델을 훈련시키고, 검증 Fold를 이용하여 정확도를 측정합니다.
동시에 훈련 과정에서 구한 parameter 값들을 저장합니다.
3. 1-2번 과정을 k번 반복합니다.
이 때, 한 번 선정한 검증 Fold를 중복하여 선택하지 않습니다.
4. 전체 시험 정확도의 평균을 k에 대한 모델의 정확도로 이용합니다.
이 때, 저장한 parameter 값들에 대한 평균을 내어 최종적인 매개 변수로 이용합니다.

```python
  print('cross validation : {:.2f}% '.format(np.mean(cross_val_score(rf,kf_data,kf_label,cv=5))*100))
```
-> rf는 모델 cv는 나누는 횟수

## Parameter Tuning

### GridSearch 

모델에는 여러가지 파라미터가 들어갑니다. SVC의 경우 Soft, Hard 마진의 정도를 결정하는 'C' 커널 함수를 결정하는 'kernel' 특정 커널에서 얼마나 세세하게 볼것인지를 결정하는 'gamma' 등 <br>
파라미터를 어떻게 결정하느냐에 따라 모델이 잘 학습하거나 잘 학습하지 못하는 경우가 발생할 수 있습니다. <br>
Sklearn에서 가장 쉽게 제공하는 파라미터 튜닝 함수로 GridSearchCV 라는 함수가 있습니다. 해당 함수에 각 파라미터에 사용할 수치 리스트를 전달하면, 해당 함수는 파라미터들의 조합을 모두 시도해보며,<br>
가장 좋은 성능의 파라미터를 찾게 됩니다. 

GridSearchCV 함수는 Sklearn의 model_selection 패키지에 있습니다.<br>

```python

    from sklearn.model_selection import GridSearchCV
    rf = RandomForestClassifier()

 ```

## Ensemble

서로 다른 모델의 다양성을 고려하여 결과를 이끌어 낸다.

### 1. Voting Ensemble

이름에서 알 수 있듯이 각자의 모델이 투표를 하여 클래스를 선택하는 방식의 앙상블 입니다. <br>
Voting 앙상블은 Sklearn 자체적으로 모델로써 지원을 하며, 사용하기도 매우 쉽습니다. <br>

다시 Adult 데이터셋으로 돌아와 앙상블을 통해 기존 단일 모델보다 좋은 결과를 얻어보도록 하겠습니다.

Voting Classifier는 Sklearn의 ensemble 패키지에 있습니다.

```python
    from sklearn.neural_network import MLPClassifier
    clfs = [('LR', LogisticRegression()), ('RF', RandomForestClassifier(max_depth=5)), ('MLP', MLPClassifier()) ]

    vote_clf = VotingClassifier(clfs)   
```

### 2. Bagging, Average Blending

 Average Blending에서 회귀의 경우 각 모델들이 예측한 결과 값을 n으로 나누어 합칩니다.<br>
분류의 경우에는 각 클래스에 해당하는 확률을 n으로 나누어 합치고, 그 중 가장 높은 확률 값을 갖는 클래스를 택하는 방식입니다. 


```python
    clf = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=2019)
    clf.fit(x_train, y_train)
    print('Single Random Forest Acc : {:.2f}%'.format(clf.score(x_test, y_test)*100))
```
