---
title:  "웹크롤러(사용법)"

categories:
  - 웹크롤러
tags:
  - Blog
toc: true
toc_sticky: true
---

## 웹 크롤러 사용법

1. 웹 페이지를 크롬 드라이버로 열기 위한 코드

    ```python

        from selenium import webdriver # 필요한 모듈 로드
        import time  # 페이지 로딩을 기다려주기 위한 함수를 불러옴

        # 크롬드라이버가 저장된 경로 설정
        chrome_path = "C:\chromedriver/chromedriver.exe"
        # 크롬 드라이버 설정
        driver = webdriver.Chrome(chrome_path)
        
        # 원하는 웹페이지 주소 설정
        url = 'http://www.naver.com/'
        # 드라이버에 url 전달
        driver.get(url)
        #페이지가 열릴때까지 기다려줌
        time.sleep(2)

    ```

2. 자동 검색하는 코드

    ```python
        # driver.find_element_by_xpath는 쌍다옴표가 들어가 있으므로 '' 사용
        #element에 검색어 창에대한 xpath 등록
        element = driver.find_element_by_id("query")
        # find_element_by_id or name or xpath or class 등을 사용 가능하다.
        driver.find_element_by_id("query").click( )
        # 검색할 단어를 전달한다.
        element.send_keys(query_txt)
        # \n은 엔터키를 의미한다.
        element.send_keys("\n")
        

    ```
3. Beautiful Soup란

아주 복잡한 HTML 코드에서 지정된 특정 태그나 값을 추출할 때 사용하는 라이브러리 입니다. Selenium은 하나의 값을 지정하면 관련된 값을 모두 가져오지만 bs는 지정한 태그만 가져오게 됩니다.



4. Beautiful Soup 사용법

    ```python

        #모듈 불러오기
        from bs4 import BeautifulSoup
        html_1 = driver.page_source #현재 페이지의 전체 소스코드를 다 가져오기
        soup_1 = BeautifulSoup(html_1, 'html.parser') # parser는 파싱할때 사용(해독), 페이지가 바뀌면 다시 갱신해줘야함

        #가져올 태그의 최상위태그부터 가져온다. find(태그,클래스명), find_all을 사용하면 해당 태그의 내용을 전부 가져온다.
        content_1 = soup_1.find('div','srchResultListW').find_all('li') 
        

    ```
